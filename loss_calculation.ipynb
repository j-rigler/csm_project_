{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2eab413",
   "metadata": {},
   "source": [
    "############# SHOCK ADAPTATION FOOD SUPPLY MODEL #############\n",
    "\n",
    "\n",
    " SOPHIA BAUM - 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdafed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 10                            # number of iterations\n",
    "compensation=True                 # turn adaptation on\n",
    "limit_abs_sim=1000                  # event limits\n",
    "limit_rel_sim=0.26\n",
    "limit_dev_sim=0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c9131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ###\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9562c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import IndexSlice as idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7571d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import scipy.sparse as sprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d14819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc68c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/valentinbast/uni/compelx_sys_modelling/project/adaptive_food_supply_network-main/csm_project_\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262759d7",
   "metadata": {},
   "source": [
    "## PARAMETERS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4d9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'input/'                 # folder with parameters\n",
    "output_folder =  'results/'             # folder to write results to\n",
    "losses = 'evaluation/'                  # folder to store the refined results to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f86a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_shock = 'IND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da4733c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "a_frame = pd.read_csv(input_folder+'a_frame.csv')\n",
    "area_value = a_frame.loc[a_frame['code'] == a_shock, 'code'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56768ffe",
   "metadata": {},
   "source": [
    "## LOADING DATA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec208b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load information\n",
    "io_codes = pd.read_csv(input_folder+'io_codes_alph.csv').drop('Unnamed: 0', axis = 1)\n",
    "su_codes = pd.read_csv(input_folder+'su_codes_alph.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288b58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single indexes\n",
    "areas = np.array(sorted(set(io_codes['area'])))\n",
    "items = np.array(sorted(set(io_codes['item'])))\n",
    "processes = np.array(sorted(set(su_codes['proc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230de8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi indexes\n",
    "ai_index = pd.MultiIndex.from_product([areas, items])\n",
    "ap_index = pd.MultiIndex.from_product([areas, items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbe8998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shock: IND\n",
      "Is a_shock in a_frame index? True\n",
      "Index(['MAR', 'DZA', 'LBY', 'TUN', 'SDN', 'EGY', 'SEN', 'ETH', 'SWZ', 'SLE',\n",
      "       ...\n",
      "       'KIR', 'PYF', 'WSM', 'BLX', 'CSK', 'ANT', 'ROW', 'SCG', 'SUN', 'YUG'],\n",
      "      dtype='object', name='code', length=192)\n",
      "a_shock: IND, type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Load  further information on countries\n",
    "a_frame = pd.read_csv(input_folder+'a_frame.csv')\n",
    "# Set 'code' as the index\n",
    "a_frame.set_index('code', inplace=True)\n",
    "\n",
    "# Check if a_shock is in the index\n",
    "print(f\"a_shock: {a_shock}\")\n",
    "print(f\"Is a_shock in a_frame index? {a_shock in a_frame.index}\")\n",
    "print(a_frame.index)\n",
    "print(f\"a_shock: {a_shock}, type: {type(a_shock)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734e6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the result of the shocked simulation\n",
    "X = pd.read_csv(output_folder+'base.csv', index_col=[0,1], header=[0])\n",
    "XS_comp = pd.read_csv(output_folder + area_value + '_comp.csv', index_col=[0, 1], header=[0, 1])\n",
    "XS_no_comp = pd.read_csv(output_folder + a_shock + '_no_comp.csv', index_col=[0, 1], header=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163781bc",
   "metadata": {},
   "source": [
    "## COMPUTATIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb0dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relative loss\n",
    "RL_no_comp = XS_no_comp.copy()\n",
    "RL_comp = XS_comp.copy()\n",
    "for col in XS_no_comp.columns:\n",
    "    RL_no_comp[col] = ((X['base'] - RL_no_comp[col])/X['base']).fillna(0)\n",
    "    RL_comp[col] = ((X['base'] - RL_comp[col])/X['base']).fillna(0)  \n",
    "RL_no_comp[RL_no_comp < -1] = -1\n",
    "RL_comp[RL_comp < -1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99fd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a dataframe for the relative loss\n",
    "RL_no_comp.columns = pd.MultiIndex.from_product([[a_shock],items])\n",
    "RL_no_comp.columns.names = ['a_shock','i_shock']\n",
    "RL_no_comp.index.names = ['a_receive','i_receive'] \n",
    "RL_comp.columns = pd.MultiIndex.from_product([[a_shock],items])\n",
    "RL_comp.columns.names = ['a_shock','i_shock']\n",
    "RL_comp.index.names = ['a_receive','i_receive'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f8553b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "RL_no_comp.to_csv(losses + 'RL-' + a_shock + '_no_comp.csv')\n",
    "RL_comp.to_csv(losses + 'RL-' + a_shock + '_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25f7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute absolute loss\n",
    "AL_no_comp = XS_no_comp.copy()\n",
    "AL_comp = XS_comp.copy()\n",
    "for col in XS_no_comp.columns:\n",
    "    AL_no_comp[col] = X['base'] - XS_no_comp[col]\n",
    "    AL_comp[col] = X['base'] - XS_comp[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b451d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a dataframe for the absolute loss\n",
    "AL_no_comp.columns = pd.MultiIndex.from_product([[a_shock],items])\n",
    "AL_no_comp.columns.names = ['a_shock','i_shock']\n",
    "AL_no_comp.index.names = ['a_receive','i_receive'] \n",
    "AL_comp.columns = pd.MultiIndex.from_product([[a_shock],items])\n",
    "AL_comp.columns.names = ['a_shock','i_shock']\n",
    "AL_comp.index.names = ['a_receive','i_receive']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b8fb506",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "AL_no_comp.to_csv(losses + 'AL-' + a_shock + '_no_comp.csv')\n",
    "AL_comp.to_csv(losses + 'AL-' + a_shock + '_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04f0cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Skip resetting the index since 'a_receive' is already a column\n",
    "AL_no_comp_flat = AL_no_comp.copy()\n",
    "AL_comp_flat = AL_comp.copy()\n",
    "\n",
    "# Step 2: Flatten column MultiIndex only if necessary\n",
    "if isinstance(AL_no_comp_flat.columns, pd.MultiIndex):\n",
    "    AL_no_comp_flat.columns = ['_'.join(filter(None, col)) for col in AL_no_comp_flat.columns]\n",
    "if isinstance(AL_comp_flat.columns, pd.MultiIndex):\n",
    "    AL_comp_flat.columns = ['_'.join(filter(None, col)) for col in AL_comp_flat.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "753d0396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL_no_comp_flat columns: Index(['IND_Abaca', 'IND_Alcohol, Non-Food', 'IND_Apples and products',\n",
      "       'IND_Asses', 'IND_Bananas', 'IND_Barley and products', 'IND_Beans',\n",
      "       'IND_Beer', 'IND_Beverages, Alcoholic', 'IND_Beverages, Fermented',\n",
      "       ...\n",
      "       'IND_Sweet potatoes', 'IND_Sweeteners, Other',\n",
      "       'IND_Tea (including mate)', 'IND_Tobacco', 'IND_Tomatoes and products',\n",
      "       'IND_Vegetables, Other', 'IND_Wheat and products', 'IND_Wine',\n",
      "       'IND_Wool (Clean Eq.)', 'IND_Yams'],\n",
      "      dtype='object', length=123)\n",
      "a_frame columns: Index(['area', 'index', 'region', 'color', 'lat', 'lng', 'population'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"AL_no_comp_flat columns:\", AL_no_comp_flat.columns)\n",
    "print(\"a_frame columns:\", a_frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9c0c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add area as a column if it’s currently the index\n",
    "if AL_no_comp.index.names[0] == 'a_receive':\n",
    "    AL_no_comp = AL_no_comp.reset_index()\n",
    "\n",
    "# Flatten and prep\n",
    "AL_no_comp_flat = AL_no_comp.copy()\n",
    "if isinstance(AL_no_comp_flat.columns, pd.MultiIndex):\n",
    "    AL_no_comp_flat.columns = ['_'.join(filter(None, col)) for col in AL_no_comp_flat.columns]\n",
    "\n",
    "# Merge on 'a_receive' (formerly index) and 'area'\n",
    "AL_no_comp_pc = AL_no_comp_flat.merge(\n",
    "    a_frame[['area', 'population']],\n",
    "    left_on='a_receive',\n",
    "    right_on='area'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0558b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Ensure 'a_receive' is a column (reset index if needed)\n",
    "if AL_no_comp.index.names[0] == 'a_receive':\n",
    "    AL_no_comp = AL_no_comp.reset_index()\n",
    "if AL_comp.index.names[0] == 'a_receive':\n",
    "    AL_comp = AL_comp.reset_index()\n",
    "\n",
    "# --- STEP 2: Flatten column MultiIndex if needed\n",
    "AL_no_comp_flat = AL_no_comp.copy()\n",
    "AL_comp_flat = AL_comp.copy()\n",
    "\n",
    "if isinstance(AL_no_comp_flat.columns, pd.MultiIndex):\n",
    "    AL_no_comp_flat.columns = ['_'.join(filter(None, col)) for col in AL_no_comp_flat.columns]\n",
    "if isinstance(AL_comp_flat.columns, pd.MultiIndex):\n",
    "    AL_comp_flat.columns = ['_'.join(filter(None, col)) for col in AL_comp_flat.columns]\n",
    "\n",
    "# --- STEP 3: Merge population info from a_frame\n",
    "AL_no_comp_pc = AL_no_comp_flat.merge(\n",
    "    a_frame[['area', 'population']],\n",
    "    left_on='a_receive',\n",
    "    right_on='area',\n",
    "    how='left'  # or 'inner' if you're sure all areas match\n",
    ")\n",
    "\n",
    "AL_comp_pc = AL_comp_flat.merge(\n",
    "    a_frame[['area', 'population']],\n",
    "    left_on='a_receive',\n",
    "    right_on='area',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- STEP 4: Normalize per capita for all 'IND_' columns\n",
    "for col in AL_no_comp_pc.columns:\n",
    "    if col.startswith('IND_'):\n",
    "        AL_no_comp_pc[col] = AL_no_comp_pc[col] / AL_no_comp_pc['population']\n",
    "\n",
    "for col in AL_comp_pc.columns:\n",
    "    if col.startswith('IND_'):\n",
    "        AL_comp_pc[col] = AL_comp_pc[col] / AL_comp_pc['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca934a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize per capita only for food item columns\n",
    "for col in AL_no_comp_pc.columns:\n",
    "    if col.startswith('IND_'):\n",
    "        AL_no_comp_pc[col] = AL_no_comp_pc[col] / AL_no_comp_pc['population']\n",
    "\n",
    "for col in AL_comp_pc.columns:\n",
    "    if col.startswith('IND_'):\n",
    "        AL_comp_pc[col] = AL_comp_pc[col] / AL_comp_pc['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d79d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_no_comp_pc.loc[:, AL_no_comp_pc.columns != 'population'] *= 1000\n",
    "AL_comp_pc.loc[:, AL_comp_pc.columns != 'population'] *= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a259a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_no_comp_pc.to_csv(losses + 'AL-' + str(a_frame.loc[a_shock, 'index']) + '_no_comp.csv')\n",
    "AL_comp_pc.to_csv(losses + 'AL-' + str(a_frame.loc[a_shock, 'index']) + '_comp.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
